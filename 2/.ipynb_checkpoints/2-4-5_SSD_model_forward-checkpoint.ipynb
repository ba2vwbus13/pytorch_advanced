{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#パッケージのimport\n",
    "from math import sqrt\n",
    "from itertools import product\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace)\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU(inplace)\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace)\n",
      "  (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "  (31): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "  (32): ReLU(inplace)\n",
      "  (33): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (34): ReLU(inplace)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def make_vgg():\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    \n",
    "    cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'MC', 512, 512, 512, 'M', 512, 512, 512]\n",
    "    \n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        elif v == 'MC':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)]\n",
    "        else:\n",
    "            cond2d = nn.Conv2d(in_channels, v, kernel_size=3, padding = 1)\n",
    "            layers += [cond2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "            \n",
    "    pool5 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "    conv6 = nn.Conv2d(512, 1024, kernel_size=3, padding=6, dilation=6)\n",
    "    conv7 = nn.Conv2d(1024, 1024, kernel_size=1)\n",
    "    layers += [pool5, conv6, nn.ReLU(inplace=True), conv7, nn.ReLU(inplace=True)]\n",
    "    return nn.ModuleList(layers)\n",
    "\n",
    "vgg_test = make_vgg()\n",
    "print(vgg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def make_extras():\n",
    "    layers = []\n",
    "    in_channels = 1024\n",
    "    cfg = [256, 512, 128, 256, 128, 256, 128, 256]\n",
    "    layers += [nn.Conv2d(in_channels, cfg[0], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[0], cfg[1], kernel_size=(3), stride=2, padding=1)]\n",
    "    layers += [nn.Conv2d(cfg[1], cfg[2], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[2], cfg[3], kernel_size=(3), stride=2, padding=1)]\n",
    "    layers += [nn.Conv2d(cfg[3], cfg[4], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[4], cfg[5], kernel_size=(3))]\n",
    "    layers += [nn.Conv2d(cfg[5], cfg[6], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[6], cfg[7], kernel_size=(3))]\n",
    "    \n",
    "    return nn.ModuleList(layers)\n",
    "\n",
    "extras_test = make_extras()\n",
    "print(extras_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (2): Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def make_loc_conf(num_classes=21, bbox_aspect_num=[4, 6, 6, 6, 4, 4]):\n",
    "    loc_layers = []\n",
    "    conf_layers = []\n",
    "    \n",
    "    loc_layers += [nn.Conv2d(512, bbox_aspect_num[0]*4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(512, bbox_aspect_num[0]*num_classes, kernel_size=3, padding=1)]\n",
    "    \n",
    "    loc_layers += [nn.Conv2d(1024, bbox_aspect_num[1]*4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(1024, bbox_aspect_num[1]*num_classes, kernel_size=3, padding=1)]\n",
    "    \n",
    "    loc_layers += [nn.Conv2d(512, bbox_aspect_num[2]*4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(512, bbox_aspect_num[2]*num_classes, kernel_size=3, padding=1)]\n",
    "    \n",
    "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[3]*4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[3]*num_classes, kernel_size=3, padding=1)]\n",
    "\n",
    "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[4]*4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[4]*num_classes, kernel_size=3, padding=1)]\n",
    "    \n",
    "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[5]*4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[5]*num_classes, kernel_size=3, padding=1)]\n",
    "    \n",
    "    return nn.ModuleList(loc_layers), nn.ModuleList(conf_layers)\n",
    "\n",
    "loc_test, conf_test = make_loc_conf()\n",
    "print(loc_test)\n",
    "print(conf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    \\nclass L2Norm(nn.Module):\\n    def __init__(self, input_channels=512, scale=20):\\n        super(L2Norm, self).__init__()  # 親クラスのコンストラクタ実行\\n        self.weight = nn.Parameter(torch.Tensor(input_channels))\\n        self.scale = scale  # 係数weightの初期値として設定する値\\n        self.reset_parameters()  # パラメータの初期化\\n        self.eps = 1e-10\\n\\n    def reset_parameters(self):\\n        #結合パラメータを大きさscaleの値にする初期化を実行\\n        init.constant_(self.weight, self.scale)  # weightの値がすべてscale（=20）になる\\n\\n    def forward(self, x):\\n        #38×38の特徴量に対して、512チャネルにわたって2乗和のルートを求めた\\n        #38×38個の値を使用し、各特徴量を正規化してから係数をかけ算する層\\n\\n        # 各チャネルにおける38×38個の特徴量のチャネル方向の2乗和を計算し、\\n        # さらにルートを求め、割り算して正規化する\\n        # normのテンソルサイズはtorch.Size([batch_num, 1, 38, 38])になります\\n        norm = x.pow(2).sum(dim=1, keepdim=True).sqrt()+self.eps\\n        x = torch.div(x, norm)\\n\\n        # 係数をかける。係数はチャネルごとに1つで、512個の係数を持つ\\n        # self.weightのテンソルサイズはtorch.Size([512])なので\\n        # torch.Size([batch_num, 512, 38, 38])まで変形します\\n        weights = self.weight.unsqueeze(\\n            0).unsqueeze(2).unsqueeze(3).expand_as(x)\\n        out = weights * x\\n\\n        return out\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class L2Norm(nn.Module):\n",
    "    def __init__(self, input_channels=512, scale=20):\n",
    "        super(L2Norm, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor(input_channels))\n",
    "        self.scale = scale\n",
    "        self.reset_parameters()\n",
    "        self.eps = 1e-10\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        init.constant_(self.weight, self.scale)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        norm = x.pwd(2).sum(dim=1, keepdim=True).sqrt()+self.eps\n",
    "        x = torch.div(x, norm)\n",
    "        weights = self.weight.unsqueeze(0).unsqueeze(2).unsqueeze(3).expand_as(x)        \n",
    "        out = weights * x\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBox(object):\n",
    "    def __init__(self, cfg):\n",
    "        super(DBox, self).__init__()\n",
    "        self.image_size = cfg['input_size']\n",
    "        self.feature_maps = cfg['feature_maps']\n",
    "        self.num_priors = len(cfg['feature_maps'])\n",
    "        self.steps = cfg['steps']\n",
    "        self.min_sizes = cfg['min_sizes']\n",
    "        self.max_sizes = cfg['max_sizes']\n",
    "        self.aspect_ratios = cfg['aspect_ratios']\n",
    "        \n",
    "    def make_dbox_list(self):\n",
    "        mean = []\n",
    "        for k, f in enumerate(self.feature_maps):\n",
    "            for i, j in product(range(f), repeat=2):\n",
    "                f_k = self.image_size / self.steps[k]\n",
    "                cx = (j+0.5)/f_k\n",
    "                cy = (i+0.5)/f_k\n",
    "                \n",
    "                s_k = self.min_sizes[k]/self.image_size\n",
    "                mean += [cx, cy, s_k, s_k]\n",
    "                \n",
    "                s_k_prime = sqrt(s_k * (self.max_sizes[k]/self.image_size))\n",
    "                mean += [cx, cy, s_k_prime, s_k_prime]\n",
    "                \n",
    "                for ar in self.aspect_ratios[k]:\n",
    "                    mean += [cx, cy, s_k*sqrt(ar), s_k/sqrt(ar)]\n",
    "                    mean += [cy, cy, s_k/sqrt(ar), s_k*sqrt(ar)]\n",
    "                    \n",
    "        output = torch.Tensor(mean).view(-1, 4)\n",
    "        output.clamp_(max=1, min=0)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.070711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.070711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.070711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.070711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.070711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.070711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.070711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8702</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8703</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.502046</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8704</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8705</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.775328</td>\n",
       "      <td>0.775328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8706</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8707</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.502046</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8708</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8709</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.775328</td>\n",
       "      <td>0.775328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8710</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8711</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.502046</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8712</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8713</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.775328</td>\n",
       "      <td>0.775328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8714</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8715</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.502046</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8716</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8717</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.775328</td>\n",
       "      <td>0.775328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8718</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8719</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.502046</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8720</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8721</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.775328</td>\n",
       "      <td>0.775328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8722</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8723</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.502046</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8724</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8725</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.775328</td>\n",
       "      <td>0.775328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8726</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8727</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.502046</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8728</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.961249</td>\n",
       "      <td>0.961249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.622254</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8732 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3\n",
       "0     0.013333  0.013333  0.100000  0.100000\n",
       "1     0.013333  0.013333  0.141421  0.141421\n",
       "2     0.013333  0.013333  0.141421  0.070711\n",
       "3     0.013333  0.013333  0.070711  0.141421\n",
       "4     0.040000  0.013333  0.100000  0.100000\n",
       "5     0.040000  0.013333  0.141421  0.141421\n",
       "6     0.040000  0.013333  0.141421  0.070711\n",
       "7     0.013333  0.013333  0.070711  0.141421\n",
       "8     0.066667  0.013333  0.100000  0.100000\n",
       "9     0.066667  0.013333  0.141421  0.141421\n",
       "10    0.066667  0.013333  0.141421  0.070711\n",
       "11    0.013333  0.013333  0.070711  0.141421\n",
       "12    0.093333  0.013333  0.100000  0.100000\n",
       "13    0.093333  0.013333  0.141421  0.141421\n",
       "14    0.093333  0.013333  0.141421  0.070711\n",
       "15    0.013333  0.013333  0.070711  0.141421\n",
       "16    0.120000  0.013333  0.100000  0.100000\n",
       "17    0.120000  0.013333  0.141421  0.141421\n",
       "18    0.120000  0.013333  0.141421  0.070711\n",
       "19    0.013333  0.013333  0.070711  0.141421\n",
       "20    0.146667  0.013333  0.100000  0.100000\n",
       "21    0.146667  0.013333  0.141421  0.141421\n",
       "22    0.146667  0.013333  0.141421  0.070711\n",
       "23    0.013333  0.013333  0.070711  0.141421\n",
       "24    0.173333  0.013333  0.100000  0.100000\n",
       "25    0.173333  0.013333  0.141421  0.141421\n",
       "26    0.173333  0.013333  0.141421  0.070711\n",
       "27    0.013333  0.013333  0.070711  0.141421\n",
       "28    0.200000  0.013333  0.100000  0.100000\n",
       "29    0.200000  0.013333  0.141421  0.141421\n",
       "...        ...       ...       ...       ...\n",
       "8702  0.833333  0.166667  1.000000  0.502046\n",
       "8703  0.166667  0.166667  0.502046  1.000000\n",
       "8704  0.166667  0.500000  0.710000  0.710000\n",
       "8705  0.166667  0.500000  0.775328  0.775328\n",
       "8706  0.166667  0.500000  1.000000  0.502046\n",
       "8707  0.500000  0.500000  0.502046  1.000000\n",
       "8708  0.500000  0.500000  0.710000  0.710000\n",
       "8709  0.500000  0.500000  0.775328  0.775328\n",
       "8710  0.500000  0.500000  1.000000  0.502046\n",
       "8711  0.500000  0.500000  0.502046  1.000000\n",
       "8712  0.833333  0.500000  0.710000  0.710000\n",
       "8713  0.833333  0.500000  0.775328  0.775328\n",
       "8714  0.833333  0.500000  1.000000  0.502046\n",
       "8715  0.500000  0.500000  0.502046  1.000000\n",
       "8716  0.166667  0.833333  0.710000  0.710000\n",
       "8717  0.166667  0.833333  0.775328  0.775328\n",
       "8718  0.166667  0.833333  1.000000  0.502046\n",
       "8719  0.833333  0.833333  0.502046  1.000000\n",
       "8720  0.500000  0.833333  0.710000  0.710000\n",
       "8721  0.500000  0.833333  0.775328  0.775328\n",
       "8722  0.500000  0.833333  1.000000  0.502046\n",
       "8723  0.833333  0.833333  0.502046  1.000000\n",
       "8724  0.833333  0.833333  0.710000  0.710000\n",
       "8725  0.833333  0.833333  0.775328  0.775328\n",
       "8726  0.833333  0.833333  1.000000  0.502046\n",
       "8727  0.833333  0.833333  0.502046  1.000000\n",
       "8728  0.500000  0.500000  0.880000  0.880000\n",
       "8729  0.500000  0.500000  0.961249  0.961249\n",
       "8730  0.500000  0.500000  1.000000  0.622254\n",
       "8731  0.500000  0.500000  0.622254  1.000000\n",
       "\n",
       "[8732 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssd_cfg = {\n",
    "    'num_classes':21,\n",
    "    'input_size':300,\n",
    "    'bbox_aspect_num':[4,6,6,6,4,4],\n",
    "    'feature_maps':[38, 19, 10, 5, 3, 1],\n",
    "    'steps':[8, 16, 32, 64, 100, 300],\n",
    "    'min_sizes':[30, 60, 111, 162, 213, 264],\n",
    "    'max_sizes':[60, 111, 162, 213, 254, 315],\n",
    "    'aspect_ratios':[[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
    "}\n",
    "\n",
    "dbox = DBox(ssd_cfg)\n",
    "dbox_list = dbox.make_dbox_list()\n",
    "\n",
    "pd.DataFrame(dbox_list.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSD(\n",
      "  (vgg): ModuleList(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (31): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "    (32): ReLU(inplace)\n",
      "    (33): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (34): ReLU(inplace)\n",
      "  )\n",
      "  (extras): ModuleList(\n",
      "    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (L2Norm): L2Norm()\n",
      "  (loc): ModuleList(\n",
      "    (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (conf): ModuleList(\n",
      "    (0): Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SSD(nn.Module):\n",
    "    def __init__(self, phase, cfg):\n",
    "        super(SSD, self).__init__()\n",
    "        self.phase = phase\n",
    "        self.num_classes = cfg['num_classes']\n",
    "        \n",
    "        self.vgg = make_vgg()\n",
    "        self.extras = make_extras()\n",
    "        self.L2Norm = L2Norm()\n",
    "        self.loc, self.conf = make_loc_conf(cfg['num_classes'], cfg['bbox_aspect_num'])\n",
    "        \n",
    "        dbox = DBox(cfg)\n",
    "        self.dbox_list = dbox.make_dbox_list()\n",
    "        \n",
    "        if phase == 'inference':\n",
    "            self.detect = Detect()\n",
    "            \n",
    "ssd_test = SSD(phase='train', cfg=ssd_cfg)\n",
    "print(ssd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(loc, dbox_list):\n",
    "    boxes = torch.cat((dbox_list[:,:2] + loc[:, :2]*0.1 * dbox_list[:,2:],\n",
    "                       dbox_list[:,2:] * torch.exp(loc[:,2:]*0.2)), dim=1)\n",
    "    boxes[:, :2] -= boxes[:, 2:] / 2\n",
    "    boxes[:, 2:] += boxes[:, :2]\n",
    "    \n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nm_suppression(boxes, scores, overlap=0.45, top_k=200):\n",
    "    count = 0\n",
    "    keep = scores.new(socores.size(0)).zeros_().long()\n",
    "    \n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    area = torch.mul(x2-x1, y2-y1)\n",
    "    \n",
    "    tmp_x1 = boxes.new()\n",
    "    tmp_y1 = boxes.new()\n",
    "    tmp_x2 = boxes.new()\n",
    "    tmp_y2 = boxes.new()\n",
    "    tmp_w = boxes.new()\n",
    "    tmp_h = boxes.new()\n",
    "    \n",
    "    v, idx = scores.sort(0)\n",
    "    \n",
    "    idx = idx[-top_k:]\n",
    "    \n",
    "    while idx.numel():\n",
    "        i = idx[-1]\n",
    "        \n",
    "        keep[count] = i\n",
    "        count += 1\n",
    "        \n",
    "        if idx.size(0) == 1:\n",
    "            break\n",
    "            \n",
    "        idx = idx[:-1]\n",
    "        \n",
    "        torch.index_select(x1, 0, idx, out=tmp_x1)\n",
    "        torch.index_select(y1, 0, idx, out=tmp_y1)\n",
    "        torch.index_select(x2, 0, idx, out=tmp_x2)\n",
    "        torch.index_select(y2, 0, idx, out=tmp_y2)\n",
    "        \n",
    "        tmp_x1 = torch.clamp(tmp_x1, min=x1[i])\n",
    "        tmp_y1 = torch.clamp(tmp_y1, min=y1[i])\n",
    "        tmp_x2 = torch.clamp(tmp_x2, max=x2[i])\n",
    "        tmp_y2 = torch.clamp(tmp_y2, max=y2[i])\n",
    "        \n",
    "        tmp_w.resize_as_(tmp_x2)\n",
    "        tmp_h.resize_as_(tmp_y2)\n",
    "        \n",
    "        tmp_w = tmp_x2 - tmp_x1\n",
    "        tmp_h = tmp_y2 - tmp_y1\n",
    "        \n",
    "        tmp_w = torch.clamp(tmp_w, min=0.0)\n",
    "        tmp_h = torch.clamp(tmp_h, min=0.0)\n",
    "        \n",
    "        inter = tmp_w * tmp_h\n",
    "        \n",
    "        rem_area = torch.index_select(area, 0, idx)\n",
    "        union = (remarea - inter) + area[i]\n",
    "        IoU = inter/union\n",
    "        \n",
    "        idx = idx[IoU.le(overlab)]\n",
    "        \n",
    "    return keep, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detect(Function):\n",
    "    def __init__(self, conf_thresh=0.01, top_k=200, nms_thresh=0.45):\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.conf_thresh = conf_thresh\n",
    "        self.top_k = top_k\n",
    "        self.nms_tresh = nms_thresh\n",
    "        \n",
    "    def forward(self, loc_data, conf_data, dbox_list):\n",
    "        num_batch = loc_data.size(0)\n",
    "        num_dbox = loc_data.size(1)\n",
    "        num_classes = conf_data.size(2)\n",
    "        \n",
    "        conf_data = self.softmax(conf_data)\n",
    "        \n",
    "        output = torch.zeros(num_batch, num_classes, self.top_k, 5)\n",
    "        \n",
    "        conf_preds = conf_data.transpose(2, 1)\n",
    "        \n",
    "        for i in range(num_batch):\n",
    "            decoded_boxes = decode(loc_data[i], dbox_list)\n",
    "            \n",
    "            conf_scores = conf_preds[i].clone()\n",
    "            \n",
    "            for cl in range(1, num_classes):\n",
    "                c_mask = conf_scores[cl].gt(self.conf_thresh)\n",
    "                scores = conf_scores[cl][cmask]\n",
    "                if scores.nelement() == 0:\n",
    "                    continue\n",
    "                \n",
    "                l_mask = c_mask.unsqueeze(1).expand_as(decoded_boxes)\n",
    "                \n",
    "                boxes = decoded_boxes[l_mask].view(-1, 4)\n",
    "                \n",
    "                ids, count = nm_suppression(boxes, scores, self.nms_thresh, self.top_k)\n",
    "                \n",
    "                output[i, cl, :count] = torch.cat((scores[ids[:count]].unsqueeze(1), boxes[idx]), 1)\n",
    "                \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSD(nn.Module):\n",
    "    def __init__(self, phase, cfg):\n",
    "        super(SSD, self).__init__()\n",
    "        \n",
    "        self.phase = phase\n",
    "        self.num_classes = cfg['num_classes']\n",
    "        \n",
    "        self.vgg = make_vgg()\n",
    "        self.extras = make_extras()\n",
    "        self.L2Norm = L2Norm()\n",
    "        self.loc, self.conf = make_loc_conf(cfg['num_classes'], cfg['bbox_aspect_num'])\n",
    "        \n",
    "        dbox = Dbox(cfg)\n",
    "        self.dbox_list = dbox.make_dbox_list()\n",
    "        \n",
    "        if phase == 'inference':\n",
    "            self.detect = Detect()\n",
    "            \n",
    "    def  forward(self, x):\n",
    "        sources = list()\n",
    "        loc = list()\n",
    "        conf = list()\n",
    "        \n",
    "        for k in range(23):\n",
    "            x = self.vgg[k](x)\n",
    "            \n",
    "        source1 = self.L2Norm(x)\n",
    "        sources.append(source1)\n",
    "        \n",
    "        for k in range(23, len(self.vgg)):\n",
    "            x = self.vgg[k](x)\n",
    "        sources.append(k)\n",
    "        \n",
    "        for k, v in enumerate(self.extras):\n",
    "            x = F.relu(v(x), inplace = True)\n",
    "            if k%2 == 1:\n",
    "                sources.append(x)\n",
    "                \n",
    "        for (x, l, c) in zip(sources, self.loc, self.conf):\n",
    "            loc.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
    "            conf.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
    "            \n",
    "        loc = torch.cat([o.view(o.size(0), -1) for o in loc], 1)\n",
    "        conf = torch.cat([o.view(o.size(0), -1) for o in conf], 1)\n",
    "        \n",
    "        loc = loc.view(loc.size(0), -1, 4)\n",
    "        conf = conf.view(conf.size(0), -1, self.num_classes)\n",
    "        \n",
    "        output = (loc, conf, self.dbox_list)\n",
    "        \n",
    "        if self.phase == 'inference':\n",
    "            return self.detect(output[0], output[1], output[2])\n",
    "        else:\n",
    "            return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
